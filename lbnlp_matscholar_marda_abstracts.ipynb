{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ecdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbnlp.models.rolodex import print_models_info\n",
    "\n",
    "print_models_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2122059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the load function from the model package\n",
    "from lbnlp.models.load.matscholar_2020v1 import load\n",
    "\n",
    "ner_model = load(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a7e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!cde data download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31796317",
   "metadata": {},
   "source": [
    "From [entities database](https://figshare.com/articles/dataset/Entities_database/8184413) readme:\n",
    "\n",
    "> Each document is indexed by it's digital object identifier (DOI) which may be used to find the original article. Each document contains the following entity types: material (MAT), sample descriptor (DSC), symmetry/phase label (SPL), property (PRO), application (APL), synthesis method (SMT), and characterization method (CMT).\n",
    "\n",
    "See also published [entity normalization](https://figshare.com/articles/dataset/Entity_Normalization/8184365) json.\n",
    "\n",
    "The tags use the so-called “inside-outside-beginning” tagging scheme ([Inside–outside–beginning (tagging) - Wikipedia](https://en.m.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging))) for multi-token entities. B- means beginning, I- means inside, O means outside. So, for example, B-MAT followed by I-MAT means it’s a 2-token MAT entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob, iglob\n",
    "import os\n",
    "\n",
    "paths_headers = os.path.expanduser(\"~/Dropbox/diary/21/07/marda-dd-abstracts-data/2021-07-14/headers/*/*.txt\")\n",
    "paths_bodies = os.path.expanduser(\"~/Dropbox/diary/21/07/marda-dd-abstracts-data/2021-07-14/bodies/*/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec659c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob(paths_headers, recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob(paths_bodies, recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeddea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "doi_to_line_end = re.compile(r\"10\\.\\d{4,9}[\\s\\/\\.]+[^\\s]+\")\n",
    "\n",
    "no_dois = []\n",
    "doi_raw_to_pathkey = {}\n",
    "\n",
    "for headerfile in iglob(paths_headers, recursive=True):\n",
    "    found = False\n",
    "    with open(headerfile, encoding='utf-8') as f:\n",
    "        lines = [line.strip() for line in f]\n",
    "    for line in lines:\n",
    "        m = re.search(doi_to_line_end, line)\n",
    "        if m:\n",
    "            doi_raw_to_pathkey[m.group(0)] = \"/\".join(Path(headerfile.replace(\"_header.txt\", \"\")).parts[-2:])\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        no_dois.append(\"/\".join(Path(headerfile.replace(\"_header.txt\", \"\")).parts[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64633aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = re.compile(r\"\\s*[\\/\\.]\\s*\")\n",
    "\n",
    "doi_to_pathkey = {}\n",
    "\n",
    "for doi_raw in list(doi_raw_to_pathkey.keys()):\n",
    "    _, pref, suff = re.split(sep, doi_raw)\n",
    "    doi_to_pathkey[f\"10.{pref}/{suff}\"] = doi_raw_to_pathkey[doi_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doi_to_pathkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# for doi in tqdm(dois):\n",
    "#     assert requests.head(f\"https://doi.org/{doi}\", allow_redirects=True).status_code == 200, doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathkey_to_doi = {pk: doi for doi, pk in doi_to_pathkey.items()}\n",
    "\n",
    "doi_to_bodypath = {}\n",
    "\n",
    "for bodypath in iglob(paths_bodies, recursive=True):\n",
    "    pathkey = \"/\".join(Path(bodypath.replace(\"_body_sent.txt\", \"\")).parts[-2:])\n",
    "    if pathkey in pathkey_to_doi:\n",
    "        doi_to_bodypath[pathkey_to_doi[pathkey]] = bodypath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aec2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doi_to_bodypath))\n",
    "assert len(doi_to_pathkey) == len(doi_to_bodypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f16fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "doi_to_tags = {}\n",
    "\n",
    "def get_tags(item):\n",
    "    doi, bodypath = item\n",
    "    with open(bodypath, encoding='utf-8') as f:\n",
    "        doc = f.read()\n",
    "    \n",
    "    try:\n",
    "        return {doi: ner_model.tag_doc(doc)}\n",
    "    except Exception as e:\n",
    "        return {\"error\": {doi: str(e)}}\n",
    "\n",
    "errors = {}\n",
    "\n",
    "pbar = tqdm(total=len(doi_to_bodypath))\n",
    "\n",
    "# takes ~ 1 hour on my laptop. -DW\n",
    "for doi, item in zip(doi_to_bodypath, doi_to_bodypath.items()):\n",
    "    data = get_tags(item)\n",
    "    if \"error\" in data:\n",
    "        errors.update(data[\"error\"])\n",
    "    else:\n",
    "        doi_to_tags.update(data)\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doi_to_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9487bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from monty.json import MontyEncoder\n",
    "\n",
    "with open(os.path.expanduser(\"~/Dropbox/diary/21/07/doi_to_tags.json\"), \"w\") as f:\n",
    "    json.dump(doi_to_tags, f, cls=MontyEncoder, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02358a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6568d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.expanduser(\"~/Dropbox/diary/21/07/doi_to_tags.json\")) as f:\n",
    "    doi_to_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35307e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class EntityType(str, Enum):\n",
    "    MAT = \"MAT\"\n",
    "    DSC = \"DSC\"\n",
    "    SPL = \"SPL\"\n",
    "    PRO = \"PRO\"\n",
    "    APL = \"APL\"\n",
    "    SMT = \"SMT\"\n",
    "    CMT = \"CMT\"\n",
    "    # Not sure what PUT and PVL are. Including here for data validation only.\n",
    "    PUT = \"PUT\"\n",
    "    PVL = \"PVL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c94bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Entry(BaseModel):\n",
    "    doi: str # digital object identifier (DOI)\n",
    "    ne: str # named entity\n",
    "    cat: EntityType # category\n",
    "    idx_s: int # sentence index from start (first sentence => 0)\n",
    "    n_sents: int # number of sentences in this abstract\n",
    "    raw_s: Optional[str] = \"\" # raw sentence string (\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(Entry(doi=\"3\", ne=\"a\", cat=\"MAT\", idx_s=0, n_sents=1).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665b97d",
   "metadata": {},
   "source": [
    "From [entities database](https://figshare.com/articles/dataset/Entities_database/8184413) readme:\n",
    "\n",
    "> Each document is indexed by it's digital object identifier (DOI) which may be used to find the original article. Each document contains the following entity types: material (MAT), sample descriptor (DSC), symmetry/phase label (SPL), property (PRO), application (APL), synthesis method (SMT), and characterization method (CMT).\n",
    "\n",
    "See also published [entity normalization](https://figshare.com/articles/dataset/Entity_Normalization/8184365) json.\n",
    "\n",
    "The tags use the so-called “inside-outside-beginning” tagging scheme ([Inside–outside–beginning (tagging) - Wikipedia](https://en.m.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging))) for multi-token entities. B- means beginning, I- means inside, O means outside. So, for example, B-MAT followed by I-MAT means it’s a 2-token MAT entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc38fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "entries = []\n",
    "\n",
    "for doi, tags in tqdm(list(doi_to_tags.items())):\n",
    "    for idx, sentence in enumerate(tags):\n",
    "        added_raw_sentence = False\n",
    "        entries_sentence = []\n",
    "        entry = None\n",
    "        for token, label in sentence:\n",
    "            if label == \"O\":\n",
    "                if entry is not None:\n",
    "                    entries_sentence.append(entry)\n",
    "                entry = None\n",
    "                continue\n",
    "            qualifier, category = label.split(\"-\")\n",
    "            if qualifier == \"B\":\n",
    "                entry = {\n",
    "                    \"doi\": doi,\n",
    "                    \"ne\": token,\n",
    "                    \"cat\": category,\n",
    "                    \"idx_s\": idx,\n",
    "                    \"n_sents\": len(tags),\n",
    "                    \"raw_s\": (\" \".join([token for token, _ in sentence]) if not added_raw_sentence else \"\")\n",
    "                }\n",
    "                added_raw_sentence = True\n",
    "            elif qualifier == \"I\":\n",
    "                if entry is None: # (should be?) impossible in theory, but there in practice!\n",
    "                    entry = {\n",
    "                        \"doi\": doi,\n",
    "                        \"ne\": token,\n",
    "                        \"cat\": category,\n",
    "                        \"idx_s\": idx,\n",
    "                        \"n_sents\": len(tags),\n",
    "                        \"raw_s\": (\" \".join([token for token, _ in sentence]) if not added_raw_sentence else \"\")\n",
    "                    }\n",
    "                    added_raw_sentence = True\n",
    "                else:\n",
    "                    entry[\"ne\"] += f\" {token}\"\n",
    "        entries.extend(entries_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('marda-dd-abstracts-matscholar.csv', 'w') as csvfile:\n",
    "    fieldnames = [\"ne\", \"cat\", \"doi\", \"n_sents\", \"idx_s\", \"raw_s\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for e in tqdm(entries):\n",
    "        entry = Entry(**e)\n",
    "        if entry.cat not in (EntityType.PUT, EntityType.PVL):\n",
    "            # json (de)serialization so that category is a string, not a Python <enum 'EntityType'>\n",
    "            writer.writerow(json.loads(entry.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l marda-dd-abstracts-matscholar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b22fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h marda-dd-abstracts-matscholar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head marda-dd-abstracts-matscholar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip marda-dd-abstracts-matscholar.zip marda-dd-abstracts-matscholar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "dbname = \"marda_dd_abstracts\"\n",
    "client.drop_database(dbname)\n",
    "db = client[dbname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c973071",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_docs = [e for e in entries if e[\"cat\"] not in (\"PVL\", \"PUT\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import keyfilter\n",
    "\n",
    "def pick(whitelist, d):\n",
    "    return keyfilter(lambda k: k in whitelist, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_abstracts = [\n",
    "    {\"doi\": doi, \"n_sents\": n_sents}\n",
    "    for doi, n_sents in {(e[\"doi\"],e[\"n_sents\"]) for e in entry_docs}\n",
    "]\n",
    "db.abstracts.insert_many(docs_abstracts)\n",
    "db.abstracts.create_index(\"doi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82089b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4868ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_sentences = [\n",
    "    {\"doi\": doi, \"idx_s\": idx_s, \"raw_s\": raw_s}\n",
    "    for doi, idx_s, raw_s in\n",
    "    {(e[\"doi\"],e[\"idx_s\"],e[\"raw_s\"]) for e in entry_docs if e.get(\"raw_s\")}\n",
    "]\n",
    "db.sentences.insert_many(docs_sentences)\n",
    "db.sentences.create_index([(\"doi\", 1), (\"idx_s\", 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_taggings = [\n",
    "    {\"doi\": doi, \"idx_s\": idx_s, \"ne\": ne, \"cat\": cat}\n",
    "    for doi, idx_s, ne, cat in\n",
    "    {(e[\"doi\"],e[\"idx_s\"],e[\"ne\"],e[\"cat\"]) for e in entry_docs}\n",
    "]\n",
    "db.taggings.insert_many(docs_taggings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.taggings.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(db.taggings.aggregate([\n",
    "    {\"$sortByCount\": \"$ne\"}\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d642e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "entity_map = {}\n",
    "\n",
    "for path in glob(\"matscholar_entity_normalization/*.json\"):\n",
    "    with open(path) as f:\n",
    "        doc = json.load(f)\n",
    "        entity_map.update({k: v[\"most_common\"] for k, v in doc.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import assoc, dissoc\n",
    "\n",
    "docs_taggings_normalized = [\n",
    "    assoc(\n",
    "        dissoc(doc, \"_id\"),\n",
    "        \"ne\",\n",
    "        entity_map.get(doc[\"ne\"], doc[\"ne\"])\n",
    "    )\n",
    "    for doc in db.taggings.find()\n",
    "]\n",
    "db.taggings_normalized.insert_many(docs_taggings_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51533a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.taggings_normalized.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a749c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(db.taggings_normalized.aggregate([\n",
    "    {\"$sortByCount\": \"$ne\"}\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([r for r in results if r[\"count\"] >= 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a61b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([r for r in results if r[\"count\"] >= 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"matscholar_taggings_normalized_gte100_occurrences.txt\", \"w\") as f:\n",
    "    gte100 = [r for r in results if r[\"count\"] >= 100]\n",
    "    n_gte100 = len(gte100)\n",
    "    for i, r in enumerate([r for r in results if r[\"count\"] >= 100]):\n",
    "        f.write(f'{i+1:03}/{n_gte100}: ({r[\"count\"]:5})  {r[\"_id\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"resolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97560f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"pitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"line width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"LWR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"line width roughness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff78bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"LER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95eac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(r for r in results if r[\"_id\"] == \"line edge roughness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788aace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mongoexport -d marda_dd_abstracts -c abstracts -o ~/marda_dd_abstracts.abstracts.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de997fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mongoexport -d marda_dd_abstracts -c sentences -o ~/marda_dd_abstracts.sentences.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4363a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mongoexport -d marda_dd_abstracts -c taggings -o ~/marda_dd_abstracts.taggings.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mongoexport -d marda_dd_abstracts -c taggings_normalized -o ~/marda_dd_abstracts.taggings_normalized.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -kvf ~/marda_dd_abstracts.*.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3e90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lbnlp",
   "language": "python",
   "name": "lbnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
